name: COHD Concepts to RDF
on:
  workflow_dispatch:
    inputs:
      endpoint:
        description: 'Upload to SPARQL endpoint'
        required: true
        default: 'https://graphdb.dumontierlab.com/repositories/cohd-dev/statements'
      graph:
        description: 'In the Graph'
        required: true
        default: 'https://w3id.org/d2s/graph/cohd'

jobs:

  generate-rdf:
    runs-on: ubuntu-latest
    outputs:
      rdf-output: ${{ steps.stepupload.outputs.rdf_output }}

    steps:
    - uses: actions/checkout@v2

    - name: Get CSV files in working directory
      run: |-
        cp datasets/cohd/download/*.csv .
        wget -O rxnorm-drugbank-omop-mapping-CLEANED.tsv https://raw.githubusercontent.com/OHDSI/KnowledgeBase/master/LAERTES/terminology-mappings/RxNORM-to-UNII-PreferredName-To-DrugBank/rxnorm-drugbank-omop-mapping-CLEANED.tsv
        sed -e 's/"/\\"/g' -e 's/\t/","/g' -e 's/^/"/' -e 's/$/"/'  -e 's/\r//' rxnorm-drugbank-omop-mapping-CLEANED.tsv > rxnorm-drugbank-omop-mapping-CLEANED.csv

    - name: Run RML mapper
      uses: vemonet/rmlmapper-java@v4.9.0
      with:
        mapping: datasets/cohd/mapping/cohd-concepts.rml.ttl
        output: cohd-concepts-rdf.nt
        
    - name: Upload RDF output artifact
      id: stepupload
      uses: actions/upload-artifact@v1
      with:
        name: rdf-output
        path: cohd-concepts-rdf.nt

  # upload-rdf:
  #   runs-on: ubuntu-latest
  #   needs: generate-rdf
    
  #   steps:
  #   - uses: actions/checkout@v2

  #   - name: Get RDF output artifact
  #     uses: actions/download-artifact@v1
  #     with:
  #       name: rdf-output

  #   - name: Upload RDF
  #     uses: MaastrichtU-IDS/RdfUpload@master
  #     with:
  #       file: rdf-output/rdf-geonames.nt
  #       endpoint: ${{ github.event.inputs.endpoint }}
  #       user: ${{ secrets.GRAPHDB_USER }}
  #       password: ${{ secrets.GRAPHDB_PASSWORD }}
  #       graph: ${{ github.event.inputs.graph }}


  #   - name: Compute and insert HCLS descriptive metadata
  #     uses: vemonet/sparql-operations-action@v1
  #     with:
  #       file: https://github.com/MaastrichtU-IDS/d2s-scripts-repository/tree/master/sparql/compute-hcls-stats
  #       endpoint: ${{ github.event.inputs.endpoint }}
  #       user: ${{ secrets.GRAPHDB_USER }}
  #       password: ${{ secrets.GRAPHDB_PASSWORD }}
  #       inputvar: ${{ github.event.inputs.graph }}
  #       outputvar: https://w3id.org/d2s/metadata
  #       servicevar: ${{ github.event.inputs.endpoint }}

  #   - name: Run RDF to HDT
  #     uses: vemonet/rdfhdt-action@master
  #     with:
  #       input: rdf-output/rdf-geonames.nt
  #       output: hdt-geonames.hdt

  #   - name: Upload HDT output artifact
  #     uses: actions/upload-artifact@v1
  #     with:
  #       name: hdt-output
  #       path: hdt-geonames.hdt

    # - name: Connect to VPN
    #   run: |
    #     sudo apt-get install -y openconnect network-manager-openconnect
    #     echo '${{ secrets.VPN_PASSWORD }}' | sudo openconnect --passwd-on-stdin --no-xmlpost --non-inter --background --authgroup ${{ secrets.VPN_GROUP }} --user ${{ secrets.VPN_USER }} ${{ secrets.VPN_URL }}
    #     sleep 10

    # - name: Copy file via SCP
    #   uses: appleboy/scp-action@master
    #   with:
    #     host: ${{ secrets.SERVER_URL }}
    #     username: ${{ secrets.SERVER_USER }}
    #     port: 22
    #     key: ${{ secrets.SERVER_KEY }}
    #     source: "rdf-output/rdf_output.nq"
    #     target: "/data/graphdb-import"
      # ${{needs.generate-rdf.outputs.rdf_output}}
    