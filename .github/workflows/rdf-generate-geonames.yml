name: Generate GeoNames RDF using RML

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

# TODO: use workflow variables for graph URI and SPARQL endpoint URL

jobs:
  download-input:
    runs-on: ubuntu-latest
    steps: 
    - name: Download CSV
      run: |
        wget https://raw.githubusercontent.com/MaastrichtU-IDS/UM_KEN4256_KnowledgeGraphs/master/dataset-geonames-countryInfo.csv
    - name: Upload CSV input artifact
      uses: actions/upload-artifact@v1
      with:
        name: input
        path: dataset-geonames-countryInfo.csv

  generate-rdf:
    runs-on: ubuntu-latest
    needs: download-input
    outputs:
      rdf-output: ${{ steps.stepupload.outputs.rdf_output }}

    steps:
    - uses: actions/checkout@v2

    - name: Get CSV input artifact
      uses: actions/download-artifact@v1
      with:
        name: input

    - uses: vemonet/rmlmapper-java@4.8
      with:
        mapping: datasets/geonames/mapping/country_mapping.rml.ttl
        output: rdf-geonames.nt

    - name: Upload RDF output artifact
      id: stepupload
      uses: actions/upload-artifact@v1
      with:
        name: rdf-output
        path: rdf-geonames.nt

  upload-rdf:
    runs-on: ubuntu-latest
    needs: generate-rdf
    
    steps:
    - uses: actions/checkout@v2

    - name: Get RDF output artifact
      uses: actions/download-artifact@v1
      with:
        name: rdf-output

    - name: Upload file to GraphDB server
      run: |
        curl -Ffile=@rdf-output/rdf-geonames.nt 'http://upload.137.120.31.102.nip.io/upload?token=${{ secrets.GRAPHDB_UPLOAD_TOKEN }}'

    - name: Start GraphDB import
      run: |
        curl -X POST -u ${{ secrets.GRAPHDB_USER }}:${{ secrets.GRAPHDB_PASSWORD }} --header 'Content-Type: application/json' --header 'Accept: application/json' -d '{"fileNames": ["upload/rdf-geonames.nt"], "importSettings": {"context": "https://w3id.org/d2s/graph/geonames"}}' 'https://graphdb.dumontierlab.com/rest/data/import/server/test-vincent'

    # Add step to wait for GraphDB import to end

    - name: Compute and insert HCLS descriptive metadata
      uses: MaastrichtU-IDS/d2s-sparql-operations@master
      with:
        file: https://github.com/MaastrichtU-IDS/d2s-scripts-repository/tree/master/sparql/compute-hcls-stats
        endpoint: https://graphdb.dumontierlab.com/repositories/test-vincent/statements
        user: ${{ secrets.GRAPHDB_USER }}
        password: ${{ secrets.GRAPHDB_PASSWORD }}
        inputvar: https://w3id.org/d2s/graph/geonames
        outputvar: https://w3id.org/d2s/metadata
        servicevar: http://localhost:7200/repositories/test-vincent

    # - name: Run RDF to HDT
    #   run: docker run rdfhdt/hdt-cpp rdf2hdt rdf-output/rdf-geonames.nt hdt-geonames.hdt

    - name: Run RDF to HDT
      uses: vemonet/rdfhdt-action@master
      with:
        input: rdf-output/rdf-geonames.nt
        output: hdt-geonames.hdt

    - name: Upload HDT output artifact
      uses: actions/upload-artifact@v1
      with:
        name: hdt-output
        path: hdt-geonames.hdt

    # - name: Connect to VPN
    #   run: |
    #     sudo apt-get install -y openconnect network-manager-openconnect
    #     echo '${{ secrets.VPN_PASSWORD }}' | sudo openconnect --passwd-on-stdin --no-xmlpost --non-inter --background --authgroup ${{ secrets.VPN_GROUP }} --user ${{ secrets.VPN_USER }} ${{ secrets.VPN_URL }}
    #     sleep 10

    # - name: Copy file via SCP
    #   uses: appleboy/scp-action@master
    #   with:
    #     host: ${{ secrets.SERVER_URL }}
    #     username: ${{ secrets.SERVER_USER }}
    #     port: 22
    #     key: ${{ secrets.SERVER_KEY }}
    #     source: "rdf-output/rdf_output.nq"
    #     target: "/data/graphdb-import"
      # ${{needs.generate-rdf.outputs.rdf_output}}
    